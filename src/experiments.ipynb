{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a0f579",
   "metadata": {},
   "source": [
    "# AI Expariments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adeded08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmelnyk2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "\n",
    "open_api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = open_api_key\n",
    "os.environ['USER_AGENT'] = os.getenv(\"USER_AGENT\")\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3524fa86",
   "metadata": {},
   "source": [
    "**Url parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740a137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "parsed = set()\n",
    "links = [\"https://mathmod.chnu.edu.ua/\"]\n",
    "\n",
    "start_url = \"https://mathmod.chnu.edu.ua/\"\n",
    "depth = 10\n",
    "\n",
    "for i in range(depth):\n",
    "    new_links = []\n",
    "    for link in links:\n",
    "        if link not in parsed:\n",
    "            try:\n",
    "                response = requests.get(link, headers={\"User-Agent\": USER_AGENT})\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                for a in soup.find_all(\"a\", href=True):\n",
    "                    href = a[\"href\"]\n",
    "                    if href.startswith(\"/\"):\n",
    "                        href = start_url + href[1:]\n",
    "                    if href.startswith(start_url) and href not in parsed and 'pdf' not in href.lower() and 'jpg' not in href.lower() and 'png' not in href.lower() and 'jpeg' not in href.lower() and 'docx' not in href.lower() and 'doc' not in href.lower() and 'xls' not in href.lower() and 'xlsx' not in href.lower() and 'pptx' not in href.lower() and 'ppt' not in href.lower() and 'email-protection' not in href.lower() and 'mailto' not in href.lower() and 'tel' not in href.lower() and 'javascript' not in href.lower() and 'webp' not in href.lower() and 'svg' not in href.lower() and 'mp4' not in href.lower() and 'avi' not in href.lower() and 'mov' not in href.lower() and 'mkv' not in href.lower() and 'flv' not in href.lower() and 'wmv' not in href.lower() and 'mp3' not in href.lower() and 'wav' not in href.lower():\n",
    "                        new_links.append(href)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {link}: {e}\")\n",
    "            parsed.add(link)\n",
    "    links.extend(new_links)\n",
    "    links = list(set(links))  # remove duplicates\n",
    "    i += 1\n",
    "\n",
    "with open(\"links.txt\", \"w\") as f:\n",
    "    for line in links:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c48a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.vectorstores'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mlinks.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# data = file.read().replace('\\n', ',')\u001b[39;00m\n\u001b[32m      8\u001b[39m     data = file.read()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.vectorstores'"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "with open('links.txt', 'r') as file:\n",
    "    # data = file.read().replace('\\n', ',')\n",
    "    data = file.read()\n",
    "    \n",
    "links = data.split('\\n')\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=links\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "print(splits[:2])\n",
    "\n",
    "vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())\n",
    "\n",
    "vectorstore.save_local(\"../models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import pickle\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "save_path = \"../models/\"\n",
    "# with open(f\"../models/index.pkl\", \"rb\") as f:\n",
    "#     stored_data = pickle.load(f)\n",
    "\n",
    "vectorstore_init = FAISS.load_local(folder_path=\"../models/\", embeddings=embd, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Load all FAISS shards and merge them\n",
    "faiss_indexes = [vectorstore_init]\n",
    "for filename in os.listdir(save_path):\n",
    "    if filename.startswith(\"faiss_index_\"):  # Load only the FAISS shards\n",
    "        index_path = os.path.join(save_path, filename)\n",
    "        vectorstore = FAISS.load_local(index_path, embd, allow_dangerous_deserialization=True)\n",
    "        faiss_indexes.append(vectorstore)\n",
    "\n",
    "# Merge all FAISS indexes into a single one\n",
    "if faiss_indexes:\n",
    "    merged_vectorstore = faiss_indexes[0]\n",
    "    for store in faiss_indexes[1:]:\n",
    "        merged_vectorstore.merge_from(store)\n",
    "\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}) # number of documents retrieved\n",
    "\n",
    "retriever = merged_vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Please, provide as much information as possible!\n",
    "Do not say words like 'context'\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c2ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithUserError: This API key is org-scoped and requires workspace specification. Please provide 'workspace_id' parameter, or set LANGSMITH_WORKSPACE_ID environment variable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ігор Михайлович Черевко — це доктор фізико-математичних наук, професор, завідувач кафедри математичного моделювання. Він розпочав свою трудову діяльність після закінчення Чернівецького державного університету у 1978 році на посаді асистента. З 1986 року працював старшим викладачем, доцентом кафедри прикладної математики, а згодом став завідувачем кафедри математичного моделювання. Ігор Михайлович також є науковим керівником студентських наукових робіт. Він має SCOPUS Author ID: 15520902400, Web of Science Researcher ID: G-3796-2017, ORCID ID: 0000-0002-2690-2091, та профіль у Google Scholar. За свої заслуги отримав Почесну відзнаку Чернівецької обласної ради «За заслуги перед Буковиною».'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithUserError: This API key is org-scoped and requires workspace specification. Please provide 'workspace_id' parameter, or set LANGSMITH_WORKSPACE_ID environment variable.\n"
     ]
    }
   ],
   "source": [
    "rag_chain.invoke(\"Хто такий Ігор Михайлович Черевко?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
